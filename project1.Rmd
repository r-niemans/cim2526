---
title: "proj1"
author: "Rafke"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Project 1

```{r import}
library("DAAG")
library(bootstrap)
library(questionr) 
data(nassCDS)
names(nassCDS)
data <- na.omit(nassCDS)
data <- nassCDS[, c("dead", "yearVeh")]
str(data)
data$dead <- factor(data$dead, levels = c("alive","dead"), labels = c("0","1"))

```

### Question 1 

Let Y_i be an indicator variable which takes the value of 1 if an occupant died in an accident (the variable
dead) and zero otherwise and let X_i be the year of model of the vehicle (=the year that the car was produced,
the variable yearVeh). We consider the following GLM:\\ 

$$g(P(Y_i = 1 | X_i)) = β_0 + β_1X_i.$$ with $$g(p) = log (\frac{p}{1-p})$$
1. Estimate the model using the classical GLM approach.
```{r}
dead_n <- length(data$dead[data$dead==1])
dead <- as.integer(as.character(data$dead))
total_n <- nrow(data)
proportiondead <-dead/total_n
alive <-total_n-dead

dead_by_year  <- tapply(dead, data$yearVeh, sum, na.rm = TRUE)
total_by_year <- tapply(dead, data$yearVeh, length)
alive_by_year <- total_by_year - dead_by_year
prop_by_year  <- dead_by_year / total_by_year

year <- as.numeric(names(prop_by_year))
par(mfrow=c(1,1))
plot(year, prop_by_year,
     main="Proportion of the people that died",
     ylim=c(0,1), xlab="yearVeh", ylab="proportion dead")

fit.accidents <- glm(cbind(dead_by_year, alive_by_year) ~ year,
                     family = binomial(link="logit"))

ord <- order(year)
lines(year[ord], fitted(fit.accidents)[ord])
```

The plot suggests that the **proportion of occupants who died decreases as vehicle model year increases**. Older vehicles (roughly the 1950s–1970s) show higher and more variable death proportions, while for newer model years (around the mid-1980s onward) the death proportion is **low and fairly stable**, close to zero. The fitted logistic trend line slopes downward, indicating a **negative association** between vehicle year and the probability of death—consistent with improved vehicle safety in newer cars.

Distribution of the response $$Y \sim B(1,\pi_{ij})$$
Systematic part $$\eta_i= \beta_0 + \beta_1 \times yearVeh_i$$

2. Let X_10 be the car’s year for which the probability to die is 0.1, P(Y_i = 1) = 0.1. Estimate X_10. Use
non parametric bootstrap to estimate the distribution of X10 and construct a 95% confidence interval
for the _10.

We resample row indices/ bootstrap coefficients $$\beta_0, \beta_1$$ and then estimate the distribution by means of nonparametric bootstrapping results for both $$\beta$$ values.

```{r}
y <- as.integer(as.character(data$dead))
x <- data$yearVeh

B <- 2000
n <- nrow(data)

beta0 <- numeric(B)
beta1 <- numeric(B)

for (b in 1:B) {
  idx <- sample.int(n, n, replace=TRUE)
  fit_b <- glm(y[idx] ~ x[idx], family=binomial(link="logit"))
  beta_coefs<- coef(fit_b)
  beta0[b] <- beta_coefs[1]
  beta1[b] <- beta_coefs[2]
}

prob01 <- log(0.1/0.9)
X10 <- (prob01 - beta0) / beta1

```

```{r}
par(mfrow=c(1,2))
hist(beta0,nclass=50)
hist(beta1,nclass=50)
hist(X10, nclass=50)

quantile(X10, c(0.025, 0.975), na.rm=TRUE)
```

$$\beta_1 < 0$$ means: as vehicle year increases, the log-odds of dying decrease, so the probability of death goes down for newer model years.

The histogram implies that cars around the early 1970s (~ 1971-1973) correspond to a 10% death probability.

3. For the model formulated above, we focus on the odds ratio (OR) for a unit increased of the year in
which the car was produced. Estimate the OR and use parametric bootstrap to test the null hypothesis
H0 : OR= 1.

```{r}
y <- data$dead
x <- data$yearVeh
glm.fit <- glm(y ~ x, family = binomial(link="logit"), data = data)
OR_hat <- exp(coef(glm.fit)[2])
OR_hat

fit_null <- glm(y ~ 1, family=binomial)
p0 <- fitted(fit_null)[1]   

set.seed(33)
B <- 2000
n <- length(y)
OR_b <- numeric(B)

for (b in 1:B) {
  yb <- rbinom(n, 1, p0)                 # H0
  fit_b <- glm(yb ~ x, family=binomial)  # and then full model
  OR_b[b] <- exp(coef(fit_b)[2])
}

p_val <- mean(abs(log(OR_b)) >= abs(log(OR_hat)))
p_val
```

4. Consider a car that was produced in 1996. Let $$π_1996$$ be the probability to die when driving a car that
was produced in 1996. Estimate $$π_1996$$ and construct a 95% confidence interval for $$π_1996$$.

```{r}
set.seed(33)
B <- 2000
n <- nrow(data)

pi1996_b <- numeric(B)

for (b in 1:B) {
  idx <- sample.int(n, n, replace=TRUE)
  fit_b <- glm(dead ~ yearVeh, family=binomial(link="logit"), data=data[idx, ])
  pi1996_b[b] <- predict(fit_b, newdata=data.frame(yearVeh=1996), type="response")
}

fit <- glm(dead ~ yearVeh, family=binomial, data=data)
pi_hat <- predict(fit, newdata=data.frame(yearVeh=1996), type="response")
CI <- quantile(pi1996_b, c(0.025, 0.975), na.rm=TRUE)

pi_hat
CI
```
The estimated probability of dying in an accident when driving a car produced in 1996 is about 3.6–4.1% (CI 95%), hinting at a relatively small uncertainty.

## Question 2

In this question we focus on the age of the age of occupant in years (the variable ageOFocc) and the injury severity (the variable injSeverity). For the analysis, select only observations for which injSeverity is smaller than 5. Note that, after filtering, the variable injSeverity is a numerical variable with the values: 
- 0 = none
- 1 = possible injury
- 2 = no incapacity
- 3 = incapacity
- 4 = killed

1. Calculate the mean age by injury severity.

```{r}
severity_subset <- subset(nassCDS, injSeverity < 5, select = c(ageOFocc, injSeverity))
severity_subset <- na.omit(severity_subset)

severity_subset$injSeverity <- factor(severity_subset$injSeverity,
                        levels = 0:4,
                        labels = c("None","Possible injury","No incapacity","Incapacity","Killed"))

tapply(severity_subset$ageOFocc, severity_subset$injSeverity, mean)
```

2. Use a non parametric bootstrap procedure to test the null hypothesis mean age of the occupant is equal across all injury severity groups.

```{r}
fit_obs <- aov(ageOFocc ~ injSeverity, data = severity_subset)
F_obs <- summary(fit_obs)[[1]][["F value"]][1]

set.seed(33)
boot <- 2000
n <- nrow(severity_subset)
index <- 1:n
F_boot <- numeric(boot)

for (b in 1:boot) {
  d_b <- severity_subset
  d_b$injSeverity <- sample(d_b$injSeverity, replace = FALSE)
  fit_b <- aov(ageOFocc ~ injSeverity, data = d_b)
  F_boot[b] <- summary(fit_b)[[1]][["F value"]][1]
}

p_val <- mean(F_boot >= F_obs, na.rm = TRUE)
c(F_obs = F_obs, p_value = p_val)
```

F=78.30: the observed ANOVA F-statistic from your real data, which is very large, meaning the differences between group means are big relative to within-group variation.

p-value = 0.00000 (with 2000 permutations): none produced an F-statistic as large as 78.30.

```{r}
severity_subset$injSeverity <- factor(severity_subset$injSeverity)

g <- severity_subset$injSeverity
y <- severity_subset$ageOFocc

means <- tapply(y, g, mean, na.rm = TRUE)
ns    <- tapply(y, g, function(z) sum(!is.na(z)))
sds   <- tapply(y, g, sd, na.rm = TRUE)

se  <- sds / sqrt(ns)
tcr <- qt(0.975, df = ns - 1)
lower <- means - tcr * se
upper <- means + tcr * se

# Plot (mean points + CI error bars)
x <- seq_along(means)
plot(x, means, xaxt="n", xlab="injSeverity", ylab="Mean ageOfOcc",
     main="Mean occupant age by injury severity (95% CI)",
     ylim = range(c(lower, upper), na.rm=TRUE))
axis(1, at=x, labels=names(means), las=1, cex.axis=0.8)

arrows(x, lower, x, upper, angle=90, code=3, length=0.05)
points(x, means, pch=19)
```

3. Let µnone and µkilled be the mean age of occupant for the groups with injury severity “None” and
“Killed”, respectively. Use parametric bootstrap to estimate a 95% confidence interval for the difference
µnone−µkilled.

```{r}
# group stats
x_none   <- severity_subset$ageOFocc[severity_subset$injSeverity == "None"]
x_killed <- severity_subset$ageOFocc[severity_subset$injSeverity == "Killed"]

mu_none   <- mean(x_none)
mu_killed <- mean(x_killed)
sd_none   <- sd(x_none)
sd_killed <- sd(x_killed)

diff_hat <- mu_none - mu_killed

set.seed(33)
B <- 10000
diff <- numeric(B)

n_none   <- length(x_none)
n_killed <- length(x_killed)

for (b in 1:B) {
  none_sev   <- rnorm(n_none,   mean = mu_none,   sd = sd_none)
  killed_sev <- rnorm(n_killed, mean = mu_killed, sd = sd_killed)
  diff[b] <- mean(none_sev) - mean(killed_sev)
}

CI_diff <- quantile(diff, probs = c(0.025, 0.975), na.rm = TRUE)
list(diff_hat = diff_hat, CI_95 = CI_diff)

```
Negative result interval ndicated that 'None' injury severity group are younger on average than 'Killed' group occupants. Difference is 7.5-10 years.

## Question 3 

In this question we focus of the following 2 ×2 table (for the complete case analysis) for the variables seat
belt usage (the variable seatbelt) and the accident outcome (the variable dead).

```{r}
data <- na.omit(nassCDS)
seatbelt_subset <- data[, c("seatbelt","dead")]
table(seatbelt_subset$seatbelt, seatbelt_subset$dead)
```

1. Define the observation unit (Xi,Yi) for the question.
$$
Y_{ij}\in\{0,1\}
\quad\text{and}\quad
\pi = P(Y=1).
$$

```{r}
xi <- seatbelt_subset$seatbelt
y <- seatbelt_subset$dead
```

2. Calculate the odds ratio for usage of seat belt and accident outcome (dead/alive) and construct a 95%
confidence interval for the OR. You can use the R function oddsratio. What is your conclusion ? Do
you think that usage of seat belt influences the accident outcome ?

```{r}
tab <- table(xi,y)
tab
OR <- (500/17965) / (680/6928) 
OR
```

Since the OR is well below 1, wearing a seatbelt is associated with lower odds of death.

Numerically, an OR of 0.28 means the odds of dying for belted occupants are about 72% lower than for unbelted occupants 
(1-0.283 = 0.717).

3. Use non-parametric bootstrap to construct a 95%
confidence interval for the OR.

```{r}
set.seed(33)
B <- 10000
n <- nrow(severity_subset)
index <- 1:n
or_boot <- numeric(B)

OR_from_tab <- function(tt){
  if (any(tt == 0)) tt <- tt + 0.5
  (tt[2,2] * tt[1,1]) / (tt[2,1] * tt[1,2])
}

for (b in 1:B) {
  idx <- sample(index, size = n, replace = TRUE)
  d_b <- severity_subset[idx, ]
  tt  <- table(d_b$seatbelt, d_b$dead)
  tt <- tt[rownames(tab), colnames(tab)]
  or_boot[b] <- OR_from_tab(tt)
}

CI_or_np <- quantile(or_boot, probs = c(0.025, 0.975), na.rm = TRUE)
CI_or_np
```

4. Use parametric bootstrap to test the hypothesis that usage of seat belt does not influence the accident
outcome using a chi-square test for a 2 ×2 table.

```{r}
tab <- table(severity_subset$seatbelt, severity_subset$dead)

chisq_obs <- suppressWarnings(chisq.test(tab, correct = FALSE)$statistic)

set.seed(33)
B <- 10000
n_tot <- sum(tab)

p_row <- prop.table(tab, 1) %*% c(1,1)     # row marginals
p_col <- c(1,1) %*% prop.table(tab, 2)     # col marginals
p_cell <- as.vector(p_row %o% p_col)      

chisq_star <- numeric(B)

for (b in 1:B) {
  tt_vec <- as.vector(rmultinom(1, size = n_tot, prob = p_cell))
  tt <- matrix(tt_vec, nrow = 2, byrow = FALSE)
  dimnames(tt) <- dimnames(tab)
  chisq_star[b] <- suppressWarnings(chisq.test(tt, correct = FALSE)$statistic)
}

p_val <- mean(chisq_star >= chisq_obs, na.rm = TRUE)
c(chisq_obs = chisq_obs, p_value = p_val)

```


## Question 4 

In this question we focus on the variables: usage of seat belt (the variable seatbelt) and gender (the variable
sex).
1. Estimate the proportion of male (πM ) and female (πF ) who used seat belt.

```{r}
d_gender <- na.omit(nassCDS[, c("seatbelt","sex")])

if (is.factor(d_gender$seatbelt)) {
  d_gender$seatbelt01 <- as.integer(d_gender$seatbelt == levels(d_gender$seatbelt)[2])
} else {
  d_gender$seatbelt01 <- as.integer(d_gender$seatbelt)
}

pi_M <- mean(d_gender$seatbelt01[d_gender$sex == "M"])
pi_F <- mean(d_gender$seatbelt01[d_gender$sex == "F"])
c(pi_M = pi_M, pi_F = pi_F)
```

2. Test the hypothesis that the proportion of male and female that use seat belt are equal using a classical
two-samples test.
```{r}
xM <- sum(d_gender$seatbelt01[d_gender$sex == "M"] == 1)
nM <- sum(d_gender$sex == "M")
xF <- sum(d_gender$seatbelt01[d_gender$sex == "F"] == 1)
nF <- sum(d_gender$sex == "F")

prop.test(x = c(xM, xF), n = c(nM, nF), correct = FALSE)
```

3. Use non parametric bootstrap to test the hypothesis that the proportion of male and female that use
seat belt in an accidents are equal.

```{r}
set.seed(33)
B <- 10000
n <- nrow(d_gender)
index <- 1:n

delta_obs <- mean(d_gender$seatbelt01[d_gender$sex == "M"]) - mean(d_gender$seatbelt01[d_gender$sex == "F"])
delta_star <- numeric(B)

# resample rows 
for (b in 1:B) {
  idx <- sample(index, size = n, replace = TRUE)
  d_b <- d_gender[idx, ]
  delta_star[b] <- mean(d_b$seatbelt01[d_b$sex == "M"]) - mean(d_b$seatbelt01[d_b$sex == "F"])
}

p_val <- mean(abs(delta_star) >= abs(delta_obs), na.rm = TRUE)
c(delta_obs = delta_obs, p_value = p_val)

```

4. Use parametric bootstrap construct a 95% confident interval for πM−πF.

```{r}
set.seed(33)
B <- 10000

pi_M_hat <- mean(d_gender$seatbelt01[d_gender$sex == "M"])
pi_F_hat <- mean(d_gender$seatbelt01[d_gender$sex == "F"])

nM <- sum(d_gender$sex == "M")
nF <- sum(d_gender$sex == "F")

delta_par <- numeric(B)

for (b in 1:B) {
  yM <- rbinom(nM, size = 1, prob = pi_M_hat)
  yF <- rbinom(nF, size = 1, prob = pi_F_hat)
  delta_par[b] <- mean(yM) - mean(yF)
}

CI_delta <- quantile(delta_par, probs = c(0.025, 0.975), na.rm = TRUE)
list(delta_hat = pi_M_hat - pi_F_hat, CI_95 = CI_delta)
```

