---
title: "proj1"
author: "Rafke"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Project 1

```{r import}
library("DAAG")
library(bootstrap)
data(nassCDS)
names(nassCDS)
data <- na.omit(nassCDS)
data <- nassCDS[, c("dead", "yearVeh")]
str(data)
data$dead <- factor(data$dead, levels = c("alive","dead"), labels = c("0","1"))

```

### Question 1 

Let Y_i be an indicator variable which takes the value of 1 if an occupant died in an accident (the variable
dead) and zero otherwise and let X_i be the year of model of the vehicle (=the year that the car was produced,
the variable yearVeh). We consider the following GLM:\\ 

$$g(P(Y_i = 1 | X_i)) = β_0 + β_1X_i.$$ with $$g(p) = log (\frac{p}{1-p})$$
1. Estimate the model using the classical GLM approach.
```{r}
dead_n <- length(data$dead[data$dead==1])
dead <- as.integer(as.character(data$dead))
total_n <- nrow(data)
proportiondead <-dead/total_n
alive <-total_n-dead
par(mfrow=c(1,1))
plot(data$yearVeh, dead, main="Proportion of the people that died",ylim=c(0,1))
dead_by_year  <- tapply(dead, data$yearVeh, sum, na.rm = TRUE)
total_by_year <- tapply(dead, data$yearVeh, length)
alive_by_year <- total_by_year - dead_by_year
prop_by_year  <- dead_by_year / total_by_year

year <- as.numeric(names(prop_by_year))

plot(year, prop_by_year,
     main="Proportion of the people that died",
     ylim=c(0,1), xlab="yearVeh", ylab="proportion dead")

fit.accidents <- glm(cbind(dead_by_year, alive_by_year) ~ year,
                     family = binomial(link="logit"))
ord <- order(year)
lines(year[ord], fitted(fit.accidents)[ord])
```


Distribution of the response $$Y \sim B(1,\pi_{ij})$$
Systematic part $$\pi_j = f(\beta_0 + \beta_1 \times year_{10}) = f(\eta)$$

2. Let X_10 be the car’s year for which the probability to die is 0.1, P(Y_i = 1) = 0.1. Estimate X_10. Use
non parametric bootstrap to estimate the distribution of X10 and construct a 95% confidence interval
for the _10.

```{r}
p <- 0.1
G <- qlogis(p)                     
b0  <- glm$coefficients[1]
b1 <- glm$coefficients[2]
x10_hat <- (G - b0) / b1
x10_hat

set.seed(33)
boot <- 1000
n <- nrow(data)
x10_boot <- numeric(boot)

for (b in 1:boot) {
  idx <- sample.int(n, n, replace = TRUE)
  d_b <- data[idx, ]
  glm_boot <- glm(dead ~ yearVeh, data = d_b, family = binomial(link = "logit"))
  b0_boot <- coef(glm_boot)[1]
  b1_boot <- coef(glm_boot)[2]
  x10_boot[b] <- (G - b0_boot) / b1_boot
}

CI_x10 <- quantile(x10_boot, probs = c(0.025, 0.975), na.rm = TRUE)
CI_x10

```

3. For the model formulated above, we focus on the odds ratio (OR) for a unit increased of the year in
which the car was produced. Estimate the OR and use parametric bootstrap to test the null hypothesis
H0 : OR= 1.

```{r}
data$dead <- ifelse(data$dead=="alive", 1, 0)
```


```{r}
b1_hat <- glm$coefficients[2]
OR_hat <- exp(b1_hat)
OR_hat

glm0 <- glm(dead ~ 1, data = data, family = binomial(link = "logit"))
p_null <- glm(glm0) # constant probability under H0

set.seed(33)
B <- 2000
b1_null <- numeric(B)

for (i in 1:B) {
  y_star <- rbinom(n, size = 1, prob = p_null[1]) 
  d_star <- data.frame(dead = y_star, yearVeh = data$yearVeh)
  glm_star <- glm(dead ~ yearVeh, data = d_star, family = binomial(link = "logit"))
  b1_null[i] <- coef(glm_star)["yearVeh"]
}

p_val <- mean(abs(b1_null) >= abs(b1_hat), na.rm = TRUE)
p_val
```

4. Consider a car that was produced in 1996. Let $$π_1996$$ be the probability to die when driving a car that
was produced in 1996. Estimate $$π_1996$$ and construct a 95% confidence interval for $$π_1996$$.

```{r}
x0 <- 1996
eta_1996 <- glm$coefficients[1] + glm$coefficients[2] * x0
pi_1996_hat <- plogis(eta_1996)
pi_1996_hat

set.seed(33)
B <- 1000
pi_1996_boot <- numeric(B)

for (b in 1:B) {
  idx <- sample.int(n, n, replace = TRUE)
  d_b <- data[idx, ]
  glm_b <- glm(dead ~ yearVeh, data = d_b, family = binomial(link = "logit"))
  eta_b <- coef(glm_b)["(Intercept)"] + coef(glm_b)["yearVeh"] * x0
  pi_1996_boot[b] <- plogis(eta_b)
}

CI_pi_1996 <- quantile(pi_1996_boot, probs = c(0.025, 0.975), na.rm = TRUE)
CI_pi_1996
```


## Question 2

In this question we focus on the age of the age of occupant in years (the variable ageOFocc) and the injury severity (the variable injSeverity). For the analysis, select only observations for which injSeverity is smaller than 5. Note that, after filtering, the variable injSeverity is a numerical variable with the values: 
- 0 = none
- 1 = possible injury
- 2 = no incapacity
- 3 = incapacity
- 4 = killed

1. Calculate the mean age by injury severity.

```{r}
severity_subset <- subset(nassCDS, injSeverity < 5, select = c(ageOFocc, injSeverity))
severity_subset <- na.omit(severity_subset)

severity_subset$injSeverity <- factor(severity_subset$injSeverity,
                        levels = 0:4,
                        labels = c("None","Possible injury","No incapacity","Incapacity","Killed"))

tapply(severity_subset$ageOFocc, severity_subset$injSeverity, mean)
```

2. Use a non parametric bootstrap procedure to test the null hypothesis mean age of the occupant is equal across all injury severity groups.

```{r}
fit_obs <- aov(ageOFocc ~ injSeverity, data = severity_subset)
F_obs <- summary(fit_obs)[[1]][["F value"]][1]

set.seed(33)
boot <- 10000
n <- nrow(severity_subset)
index <- 1:n
F_boot <- numeric(boot)

for (b in 1:boot) {
  d_b <- severity_subset
  d_b$injSeverity <- sample(d_b$injSeverity, replace = FALSE)
  fit_b <- aov(ageOFocc ~ injSeverity, data = d_b)
  F_boot[b] <- summary(fit_b)[[1]][["F value"]][1]
}

p_val <- mean(F_boot >= F_obs, na.rm = TRUE)
c(F_obs = F_obs, p_value = p_val)
```

3. Let µnone and µkilled be the mean age of occupant for the groups with injury severity “None” and
“Killed”, respectively. Use parametric bootstrap to estimate a 95% confidence interval for the difference
µnone−µkilled.

```{r}
# group stats
x_none   <- na.omit(severity_subset$ageOFocc[severity_subset$injSeverity == "None"])
x_killed <- na.omit(severity_subset$ageOFocc[severity_subset$injSeverity == "Killed"])

mu_none   <- mean(x_none)
mu_killed <- mean(x_killed)
sd_none   <- sd(x_none)
sd_killed <- sd(x_killed)

diff_hat <- mu_none - mu_killed

set.seed(33)
B <- 10000
diff_star <- numeric(B)

n_none   <- length(x_none)
n_killed <- length(x_killed)

for (b in 1:B) {
  none_star   <- rnorm(n_none,   mean = mu_none,   sd = sd_none)
  killed_star <- rnorm(n_killed, mean = mu_killed, sd = sd_killed)
  diff_star[b] <- mean(none_star) - mean(killed_star)
}

CI_diff <- quantile(diff_star, probs = c(0.025, 0.975), na.rm = TRUE)
list(diff_hat = diff_hat, CI_95 = CI_diff)

```

## Question 3 

In this question we focus of the following 2 ×2 table (for the complete case analysis) for the variables seat
belt usage (the variable seatbelt) and the accident outcome (the variable dead).

```{r}
severity_subset <- data[, c("seatbelt","dead")]
severity_subset <- na.omit(severity_subset)
table(severity_subset$seatbelt, severity_subset$dead)
```

1. Define the observation unit (Xi,Yi) for the question.
$$
Y_{ij}\in\{0,1\}
\quad\text{and}\quad
\pi = P(Y=1).
$$

```{r}
xi <- severity_subset$seatbelt
y <- severity_subset$dead
```

2. Calculate the odds ratio for usage of seat belt and accident outcome (dead/alive) and construct a 95%
confidence interval for the OR. You can use the R function oddsratio. What is your conclusion ? Do
you think that usage of seat belt influences the accident outcome ?

```{r}
library(questionr)
tab <- table(xi,y)
odds.ratio(tab, na.rm=TRUE, level=0.95)
```

3. Use non-parametric bootstrap to construct a 95%
confidence interval for the OR.

```{r}
set.seed(33)
B <- 10000
n <- nrow(severity_subset)
index <- 1:n
or_boot <- numeric(B)

OR_from_tab <- function(tt){
  if (any(tt == 0)) tt <- tt + 0.5
  (tt[2,2] * tt[1,1]) / (tt[2,1] * tt[1,2])
}

for (b in 1:B) {
  idx <- sample(index, size = n, replace = TRUE)
  d_b <- severity_subset[idx, ]
  tt  <- table(d_b$seatbelt, d_b$dead)
  tt <- tt[rownames(tab), colnames(tab)]
  or_boot[b] <- OR_from_tab(tt)
}

CI_or_np <- quantile(or_boot, probs = c(0.025, 0.975), na.rm = TRUE)
CI_or_np
```

4. Use parametric bootstrap to test the hypothesis that usage of seat belt does not influence the accident
outcome using a chi-square test for a 2 ×2 table.

```{r}
tab <- table(severity_subset$seatbelt, severity_subset$dead)

chisq_obs <- suppressWarnings(chisq.test(tab, correct = FALSE)$statistic)

set.seed(33)
B <- 10000
n_tot <- sum(tab)

p_row <- prop.table(tab, 1) %*% c(1,1)     # row marginals
p_col <- c(1,1) %*% prop.table(tab, 2)     # col marginals
p_cell <- as.vector(p_row %o% p_col)      

chisq_star <- numeric(B)

for (b in 1:B) {
  tt_vec <- as.vector(rmultinom(1, size = n_tot, prob = p_cell))
  tt <- matrix(tt_vec, nrow = 2, byrow = FALSE)
  dimnames(tt) <- dimnames(tab)
  chisq_star[b] <- suppressWarnings(chisq.test(tt, correct = FALSE)$statistic)
}

p_val <- mean(chisq_star >= chisq_obs, na.rm = TRUE)
c(chisq_obs = chisq_obs, p_value = p_val)

```


## Question 4 

In this question we focus on the variables: usage of seat belt (the variable seatbelt) and gender (the variable
sex).
1. Estimate the proportion of male (πM ) and female (πF ) who used seat belt.

```{r}
d_gender <- na.omit(nassCDS[, c("seatbelt","sex")])

if (is.factor(d_gender$seatbelt)) {
  d_gender$seatbelt01 <- as.integer(d_gender$seatbelt == levels(d_gender$seatbelt)[2])
} else {
  d_gender$seatbelt01 <- as.integer(d_gender$seatbelt)
}

pi_M <- mean(d_gender$seatbelt01[d_gender$sex == "M"])
pi_F <- mean(d_gender$seatbelt01[d_gender$sex == "F"])
c(pi_M = pi_M, pi_F = pi_F)
```

2. Test the hypothesis that the proportion of male and female that use seat belt are equal using a classical
two-samples test.
```{r}
xM <- sum(d_gender$seatbelt01[d_gender$sex == "M"] == 1)
nM <- sum(d_gender$sex == "M")
xF <- sum(d_gender$seatbelt01[d_gender$sex == "F"] == 1)
nF <- sum(d_gender$sex == "F")

prop.test(x = c(xM, xF), n = c(nM, nF), correct = FALSE)
```

3. Use non parametric bootstrap to test the hypothesis that the proportion of male and female that use
seat belt in an accidents are equal.

```{r}
set.seed(33)
B <- 10000
n <- nrow(d_gender)
index <- 1:n

delta_obs <- mean(d_gender$seatbelt01[d_gender$sex == "M"]) - mean(d_gender$seatbelt01[d_gender$sex == "F"])
delta_star <- numeric(B)

# resample rows 
for (b in 1:B) {
  idx <- sample(index, size = n, replace = TRUE)
  d_b <- d_gender[idx, ]
  delta_star[b] <- mean(d_b$seatbelt01[d_b$sex == "M"]) - mean(d_b$seatbelt01[d_b$sex == "F"])
}

p_val <- mean(abs(delta_star) >= abs(delta_obs), na.rm = TRUE)
c(delta_obs = delta_obs, p_value = p_val)

```

4. Use parametric bootstrap construct a 95% confident interval for πM−πF.

```{r}
set.seed(33)
B <- 10000

pi_M_hat <- mean(d_gender$seatbelt01[d_gender$sex == "M"])
pi_F_hat <- mean(d_gender$seatbelt01[d_gender$sex == "F"])

nM <- sum(d_gender$sex == "M")
nF <- sum(d_gender$sex == "F")

delta_par <- numeric(B)

for (b in 1:B) {
  yM <- rbinom(nM, size = 1, prob = pi_M_hat)
  yF <- rbinom(nF, size = 1, prob = pi_F_hat)
  delta_par[b] <- mean(yM) - mean(yF)
}

CI_delta <- quantile(delta_par, probs = c(0.025, 0.975), na.rm = TRUE)
list(delta_hat = pi_M_hat - pi_F_hat, CI_95 = CI_delta)
```

